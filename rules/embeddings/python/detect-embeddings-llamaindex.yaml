rules:
  - id: detect-embeddings-llamaindex
    languages:
      - python
    severity: INFO
    message: "Detected LlamaIndex embeddings usage: Text embeddings, vector generation, or embedding model patterns"
    pattern-either:
      # Embedding imports
      - pattern: from llama_index.embeddings.openai import OpenAIEmbedding
      - pattern: from llama_index.embeddings import $EMBEDDINGS
      - pattern: from llama_index.core.embeddings import BaseEmbedding
      - pattern: from llama_index.embeddings.huggingface import HuggingFaceEmbedding
      # Settings configuration with embeddings
      - pattern: Settings.embed_model = OpenAIEmbedding()
      - pattern: Settings.embed_model = $EMBEDDING_MODEL
      - pattern: from llama_index.core import Settings
      # Embedding instantiation
      - pattern: $EMBEDDINGS = OpenAIEmbedding()
      - pattern: embed_model = OpenAIEmbedding(...)
      - pattern: $VAR = HuggingFaceEmbedding(...)
      # Vector index creation (implies embeddings)
      - pattern: from llama_index.core import VectorStoreIndex
      - pattern: index = VectorStoreIndex.from_documents($DOCS)
      - pattern: $INDEX = VectorStoreIndex.from_documents(...)
      # Vector store with embeddings
      - pattern: from llama_index.vector_stores.chroma import ChromaVectorStore
      - pattern: from llama_index.vector_stores import $VECTORSTORE
      - pattern: vector_store = ChromaVectorStore(...)
      - pattern: $STORE = $VECTORSTORE(...)
      # Storage context with vector store
      - pattern: from llama_index.core.storage.storage_context import StorageContext
      - pattern: storage_context = StorageContext.from_defaults(vector_store=$STORE)
      - pattern: StorageContext.from_defaults(..., vector_store=...)
      # Index creation with storage context
      - pattern: index = VectorStoreIndex.from_documents($DOCS, storage_context=$CONTEXT)
      - pattern: VectorStoreIndex.from_documents(..., storage_context=...)
      # Node parser for embeddings
      - pattern: from llama_index.core.node_parser import SimpleNodeParser
      - pattern: node_parser = SimpleNodeParser()
      - pattern: $PARSER = SimpleNodeParser(...)
      # Query engine (uses embeddings internally)
      - pattern: query_engine = index.as_query_engine()
      - pattern: $ENGINE = $INDEX.as_query_engine()
      - pattern: query_engine.query($QUERY)
      # Retriever patterns
      - pattern: from llama_index.core.retrievers import BaseRetriever
      - pattern: $INDEX.as_retriever(similarity_top_k=$K)
      - pattern: similarity_top_k=$K
      # Custom retriever with embeddings
      - pattern: |
          class CustomRetriever(BaseRetriever):
              def __init__(self, vector_index):
                  self._vector_index = vector_index
                  ...
    metadata:
      references:
        - https://docs.llamaindex.ai/en/stable/module_guides/models/embeddings/
        - https://docs.llamaindex.ai/en/stable/examples/embeddings/
      category: maintainability
      technology:
        - genAI
        - LLMs
        - embeddings
        - vector-search
        - text-embeddings
      confidence: MEDIUM
      subcategory:
        - embeddings